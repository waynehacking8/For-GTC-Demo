"""
LightRAG Service - è§£è€¦çš„ RAG æœå‹™æ¨¡çµ„

é€™æ˜¯ä¸€å€‹ç¨ç«‹çš„ Python æ¨¡çµ„ï¼Œå¯ä»¥ç›´æ¥ import ä½¿ç”¨ï¼Œç„¡éœ€é€é HTTP APIã€‚
ç›´æ¥é€£æ¥åˆ°å·²å­˜åœ¨çš„ LightRAG å„²å­˜å’Œ vLLM æœå‹™ã€‚

ä½¿ç”¨æ–¹å¼ï¼š
    from src.lib.rag.service import RAGService

    # åˆå§‹åŒ–ï¼ˆå–®ä¾‹æ¨¡å¼ï¼‰
    rag = await RAGService.get_instance()

    # æŸ¥è©¢
    result = await rag.query("æ­£å´´2024å¹´çš„EPSæ˜¯å¤šå°‘ï¼Ÿ")

    # ä¸²æµæŸ¥è©¢
    async for token in rag.query_stream("æ­£å´´2024å¹´çš„EPSæ˜¯å¤šå°‘ï¼Ÿ"):
        print(token, end="", flush=True)
"""

import os
import sys
import json
import asyncio
from typing import Optional, Dict, Any, AsyncGenerator
from pathlib import Path

# æ·»åŠ  phase3-rag åˆ° Python path
PHASE3_RAG_PATH = "/home/wayne/Desktop/LocalMind/phase3-rag"
if PHASE3_RAG_PATH not in sys.path:
    sys.path.insert(0, PHASE3_RAG_PATH)


class RAGService:
    """
    LightRAG æœå‹™å°è£é¡

    æä¾›å–®ä¾‹æ¨¡å¼çš„ RAG æœå‹™ï¼Œå¯ä»¥ç›´æ¥åœ¨ Python ä¸­ä½¿ç”¨ï¼Œ
    ç„¡éœ€é€é HTTP API å‘¼å«ã€‚
    """

    _instance: Optional['RAGService'] = None
    _initialized: bool = False

    def __init__(self):
        self.rag_system = None
        self.working_dir = "/home/wayne/Desktop/LocalMind/phase3-rag/api_rag_storage"
        self.workspace = "api_workspace"
        self.llm_model = "Qwen/Qwen3-VL-32B-Instruct"
        self.vllm_url = "http://localhost:8002/v1/chat/completions"
        self.embedding_url = "http://localhost:8003/v1/embeddings"

    @classmethod
    async def get_instance(cls) -> 'RAGService':
        """
        ç²å– RAGService å–®ä¾‹å¯¦ä¾‹

        Returns:
            RAGService: åˆå§‹åŒ–å®Œæˆçš„ RAG æœå‹™å¯¦ä¾‹
        """
        if cls._instance is None:
            cls._instance = RAGService()

        if not cls._initialized:
            await cls._instance._initialize()
            cls._initialized = True

        return cls._instance

    async def _initialize(self):
        """åˆå§‹åŒ– LightRAG ç³»çµ±"""
        try:
            # è¨­å®šç’°å¢ƒè®Šæ•¸
            os.environ['LIGHTRAG_LLM_MODEL'] = self.llm_model

            # Import LightRAG ç›¸é—œæ¨¡çµ„
            from src.rag.multimodal_system import create_multimodal_rag

            print(f"ğŸ”§ åˆå§‹åŒ– RAG æœå‹™...")
            print(f"   å·¥ä½œç›®éŒ„: {self.working_dir}")
            print(f"   LLM æ¨¡å‹: {self.llm_model}")

            self.rag_system = await create_multimodal_rag(
                working_dir=self.working_dir,
                workspace=self.workspace,
                llm_model_name=self.llm_model,
                embedding_model_name="BAAI/bge-m3",
                chunk_token_size=1200,
                chunk_overlap_token_size=100,
                llm_model_max_async=32,
                entity_extract_max_gleaning=0,
                max_parallel_insert=8,
                enable_monitoring=True,
                enable_logging=True,
            )

            print("âœ… RAG æœå‹™åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            print(f"âŒ RAG æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
            raise

    async def query(
        self,
        query_text: str,
        mode: str = "naive",
        top_k: int = 20,
        system_prompt: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åŸ·è¡Œ RAG æŸ¥è©¢

        Args:
            query_text: æŸ¥è©¢æ–‡å­—
            mode: æŸ¥è©¢æ¨¡å¼ (naive, local, global, hybrid)
            top_k: è¿”å›çµæœæ•¸é‡
            system_prompt: è‡ªå®šç¾©ç³»çµ±æç¤ºè©

        Returns:
            åŒ…å« answer, success, sources ç­‰çš„å­—å…¸
        """
        if self.rag_system is None:
            raise RuntimeError("RAG æœå‹™å°šæœªåˆå§‹åŒ–ï¼Œè«‹å…ˆå‘¼å« get_instance()")

        try:
            result = await self.rag_system.query(
                query_text=query_text,
                mode=mode,
                top_k=top_k,
                return_sources=True,
                use_cache=True,
                system_prompt=system_prompt,
            )
            return result
        except Exception as e:
            return {
                "answer": f"æŸ¥è©¢éŒ¯èª¤: {str(e)}",
                "success": False,
                "sources": [],
                "error": str(e)
            }

    async def query_stream(
        self,
        query_text: str,
        mode: str = "naive",
        top_k: int = 20,
        system_prompt: Optional[str] = None
    ) -> AsyncGenerator[str, None]:
        """
        ä¸²æµ RAG æŸ¥è©¢ - é€ token è¿”å›

        Args:
            query_text: æŸ¥è©¢æ–‡å­—
            mode: æŸ¥è©¢æ¨¡å¼ (naive, local, global, hybrid)
            top_k: è¿”å›çµæœæ•¸é‡
            system_prompt: è‡ªå®šç¾©ç³»çµ±æç¤ºè©

        Yields:
            str: æ¯å€‹ç”Ÿæˆçš„ token
        """
        if self.rag_system is None:
            raise RuntimeError("RAG æœå‹™å°šæœªåˆå§‹åŒ–ï¼Œè«‹å…ˆå‘¼å« get_instance()")

        try:
            async for token in self.rag_system.query_stream(
                query_text=query_text,
                mode=mode,
                top_k=top_k,
                system_prompt=system_prompt,
            ):
                yield token
        except Exception as e:
            yield f"\n\n[éŒ¯èª¤: {str(e)}]"

    async def get_context(
        self,
        query_text: str,
        mode: str = "naive",
        top_k: int = 20
    ) -> str:
        """
        åªç²å–çŸ¥è­˜åº«ä¸Šä¸‹æ–‡ï¼Œä¸ç”Ÿæˆå›ç­”

        ç”¨æ–¼éœ€è¦è‡ªè¡Œè™•ç†ä¸Šä¸‹æ–‡çš„å ´æ™¯

        Args:
            query_text: æŸ¥è©¢æ–‡å­—
            mode: æŸ¥è©¢æ¨¡å¼
            top_k: è¿”å›çµæœæ•¸é‡

        Returns:
            str: çŸ¥è­˜åº«ä¸Šä¸‹æ–‡
        """
        if self.rag_system is None:
            raise RuntimeError("RAG æœå‹™å°šæœªåˆå§‹åŒ–ï¼Œè«‹å…ˆå‘¼å« get_instance()")

        try:
            from lightrag import QueryParam

            query_param = QueryParam(
                mode=mode,
                top_k=top_k,
                only_need_context=True,
            )

            context = await self.rag_system.rag.aquery(query_text, param=query_param)
            return context
        except Exception as e:
            return f"ç²å–ä¸Šä¸‹æ–‡éŒ¯èª¤: {str(e)}"

    def is_initialized(self) -> bool:
        """æª¢æŸ¥æœå‹™æ˜¯å¦å·²åˆå§‹åŒ–"""
        return self.rag_system is not None


# ä¾¿æ·å‡½æ•¸ - å¯ä»¥ç›´æ¥ import ä½¿ç”¨
async def query(query_text: str, **kwargs) -> Dict[str, Any]:
    """
    ä¾¿æ·æŸ¥è©¢å‡½æ•¸

    ä½¿ç”¨æ–¹å¼:
        from src.lib.rag.service import query
        result = await query("æ­£å´´2024å¹´çš„EPSæ˜¯å¤šå°‘ï¼Ÿ")
    """
    rag = await RAGService.get_instance()
    return await rag.query(query_text, **kwargs)


async def query_stream(query_text: str, **kwargs) -> AsyncGenerator[str, None]:
    """
    ä¾¿æ·ä¸²æµæŸ¥è©¢å‡½æ•¸

    ä½¿ç”¨æ–¹å¼:
        from src.lib.rag.service import query_stream
        async for token in query_stream("æ­£å´´2024å¹´çš„EPSæ˜¯å¤šå°‘ï¼Ÿ"):
            print(token, end="")
    """
    rag = await RAGService.get_instance()
    async for token in rag.query_stream(query_text, **kwargs):
        yield token


async def get_context(query_text: str, **kwargs) -> str:
    """
    ä¾¿æ·ç²å–ä¸Šä¸‹æ–‡å‡½æ•¸

    ä½¿ç”¨æ–¹å¼:
        from src.lib.rag.service import get_context
        context = await get_context("æ­£å´´ç‡Ÿæ”¶")
    """
    rag = await RAGService.get_instance()
    return await rag.get_context(query_text, **kwargs)


# æ¸¬è©¦ç”¨ä¸»ç¨‹å¼
if __name__ == "__main__":
    async def test():
        print("=" * 50)
        print("RAG æœå‹™æ¸¬è©¦")
        print("=" * 50)

        # æ¸¬è©¦æŸ¥è©¢
        rag = await RAGService.get_instance()

        query_text = "æ­£å´´2024å¹´çš„æ¯è‚¡ç›ˆé¤˜EPSæ˜¯å¤šå°‘ï¼Ÿ"
        print(f"\næŸ¥è©¢: {query_text}")
        print("-" * 50)

        # ä¸²æµè¼¸å‡º
        async for token in rag.query_stream(query_text, mode="naive"):
            print(token, end="", flush=True)

        print("\n")
        print("=" * 50)

    asyncio.run(test())
